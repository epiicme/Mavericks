\chapter{Implementation}\label{ch:implementation}

\section{Data Mining}
\subsubsection{Data Set}
Any neural network requires data in order to learn and become useful. As such, the training data is an important part of the learning process. For this implementation, the OpenSLR LibriSpeech ASR corpus was imported to provide training data.\\

The LibriSpeech is comprised of approximately 1000 hours of 16kHz English read speech in .flac format, and was prepared by Vassil Panayotov with the assistance of Daniel Povey. It is based on audio books from the LibriVox project that have been segmented and aligned. It contains 3 different sets, differentiated by type and size.\\ 
The first, and smallest one, is made of 6.3 GB of "clean" speech, representing approx. 100 hours. "Clean" speech refers to audio recordings where noise and disturbances that might corrupt their quality were eliminated as much as possible.\\ 
The second set is made of 23 GB of "clean" speech that represents approx. 360 hours.\\
The final set is made of 30 GB of "other" speech, representing approx. 500 hours of audio. "Other" speech refers to recordings that contain a certain degree of audio disturbance.\\
The corpus also contains smaller sets for validation and testing.\\

\subsubsection{Data processing}
As presented above, the OpenSLR corpus provides many features for training neural networks. It is especially efficient for speech recognition systems. However, the current implementation was designed to use pairs of .wav files and .txt files as input. Each .wav file represents the audio information that is encoded into the corresponding .txt file, more specifically short paragraphs.\\

Unfortunately, this data set is prepared in a different format. There is a single .txt file that corresponds to many .wav files and these are organized in bigger sets. Because of this, the data in its original form is not usable for the current neural network. To prepare the data, certain scripts were implemented in Python.\\
The first algorithm is designed to navigate a folder path and its sub-folders to convert all .flac files to .wav. It uses the os and pydub libraries.  \\
The second 



%code snippents
\lstinputlisting[language=Python, firstline=5, lastline=15]{code/FlacToWavPy.py}

\lstinputlisting[language=Python, firstline=100, lastline=110]{code/txtFileMaker.py}

\section{Model Implementation}






\section{Testing}










