\chapter{Implementation}\label{ch:implementation}

\section{Data Mining}
\subsubsection{Data Set}
Any neural network requires data in order to learn and become useful. As such, the training data is an important part of the learning process. For this implementation, the OpenSLR LibriSpeech ASR corpus was imported to provide training data.
The LibriSpeech set is comprised of approximately 1000 hours of 16kHz English read speech in .flac format, and was prepared by Vassil Panayotov with the assistance of Daniel Povey. It is based on audio books from the LibriVox project that have been segmented and aligned. It contains 3 different sets, differentiated by type and size.\\\\
The first, and smallest one, is made of 6.3 GB of "clean" speech, representing approx. 100 hours. "Clean" speech refers to audio recordings where noise and disturbances that might corrupt their quality were eliminated as much as possible.\\ 
The second set is made of 23 GB of "clean" speech that represents approx. 360 hours.
The final set is made of 30 GB of "other" speech, representing approx. 500 hours of audio. "Other" speech refers to recordings that contain a certain degree of audio disturbance.\\
The corpus also contains smaller sets for validation and testing.\\

\subsubsection{Data processing}
As presented above, the OpenSLR corpus provides many features for training neural networks. It is especially efficient for speech recognition systems. However, the current implementation was designed to use pairs of .wav and .txt files as input. Each .wav file represents the audio information that is encoded in the corresponding .txt file, more specifically short paragraphs.\\

Unfortunately, this data set is prepared in a different format. There is a single .txt file that corresponds to many .wav files and these are organized in bigger sets. Because of this, the data in its original form is not usable for the current neural network. To prepare the data, certain scripts were implemented in Python.\\

The first algorithm is designed to navigate a folder path and its sub-folders to convert all .flac files to .wav. It uses the os and pydub libraries.  \\
To access every sub-folder in the path, os.walk is used. This function returns the root folder and a list of files and directories in root, after which an internal folder becomes the new root.

\lstinputlisting[language=Python, firstline=37, lastline=51]{code/FlacToWavPy.py}

The conversion is handled by another function that uses the pydub library to load the .flac, parse the name and   export the converted .wav file.

\lstinputlisting[language=Python, firstline=25, lastline=35]{code/FlacToWavPy.py}

The second algorithm navigates the folders in the same way, by using the os.walk method. Then it checks for .txt files by parsing their name. 

\lstinputlisting[language=Python, firstline=13, lastline=22]{code/txtFileMaker.py}

The format of the text files in this audio set is known. Using this information, the file name and content is parsed, creating new text files for every paragraph that corresponds to a flac file. This is achieved by exploiting the file name in relation to the beginning and end of each paragraph inside the file.
 
\lstinputlisting[language=Python, firstline=36, lastline=51]{code/txtFileMaker.py} 
 
\section{Model Implementation}

One of the goals for this project was to research, design and compare different neural network topologies. 
Some of these were feed-forward, convolutional and recurrent. 
Continuing, some neural networks were made deep, first by adding fully connected layers to the existing type (feed-forward, CNN or RNN), and later, by changing the type (LSTM, GRU or BiRNN) and/or adding more main layers. 
Many such configurations were tested, some proving to be efficient for achieving designated goals, and some less so. \\\\
As shown in a previous chapter, the model that is used in this DSR system is a a recurrent neural network. 
This recurrent network is based on the standard LSTM cell, but used as a bidirectional layer. 
The purpose is to recognize the context of the text, to improve the prediction. 
The complete topology for the network is as follows: \\\\
\todo{INSERT NICE PICTURE DESCRIPTION HERE} \\\\
Described in figure X is the complete topology of the network used in the current implementation. It has a structure of 2-BiRNN-1-logits. In the beginning it has 2 fully connected layers, each consisting of 1024 neurons.
\lstinputlisting[language=Python, firstline=36, lastline=51]{code/txtFileMaker.py} 
Further on, the input is reshaped to be compatible with the BiRNN layer, consisting of two LSTM cells, each with 1024 neurons.
One cell is used in the "forward" direction, and the other one in the "backward" direction, with the goal of understanding the current context.
Following this step, the input is reshaped again and sent to the next fully connected layer.
The final layer, the logits layer, is used as output of the network. At this point, the original input is transformed by every layer and sent for decoding.



\section{Testing}










