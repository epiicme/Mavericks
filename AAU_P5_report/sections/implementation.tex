\chapter{Implementation}\label{ch:implementation}

\section{Data Mining}
\subsubsection{Data Set}
Any neural network requires data in order to learn and become useful. As such, the training data is an important part of the learning process. For this implementation, the OpenSLR LibriSpeech ASR corpus was imported to provide training data.\\

The LibriSpeech is comprised of approximately 1000 hours of 16kHz English read speech in .flac format, and was prepared by Vassil Panayotov with the assistance of Daniel Povey. It is based on audio books from the LibriVox project that have been segmented and aligned. It contains 3 different sets, differentiated by type and size.\\ 
The first, and smallest one, is made of 6.3 GB of "clean" speech, representing approx. 100 hours. "Clean" speech refers to audio recordings where noise and disturbances that might corrupt their quality were eliminated as much as possible.\\ 
The second set is made of 23 GB of "clean" speech that represents approx. 360 hours.\\
The final set is made of 30 GB of "other" speech, representing approx. 500 hours of audio. "Other" speech refers to recordings that contain a certain degree of audio disturbance.\\
The corpus also contains smaller sets for validation and testing.\\

\subsubsection{Data processing}
As presented above, the OpenSLR corpus provides many features for training neural networks. It is especially efficient for speech recognition systems. However, the current implementation was designed to use .wav files as input
\section{Model Implementation}

\section{Testing}
